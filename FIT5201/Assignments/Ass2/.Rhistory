library(tm)
path <- '../datasets/Task2A.txt'
text <- readLines(path)
path <- '~/gitfiles/R_playground/FIT5201/Assignments/Ass2/datasets/Task2A.txt'
text <- readLines(path)
docs <- strsplit(text, '\t')
labels <- unlist(lapply(docs, function(x) x[1]))
texts <- unlist(lapply(docs, function(x) x[2]))
indices <- c(1:length(texts))
docs <- data.frame(doc_id = indices, text=texts)
View(docs)
# create a corpus
docs <- DataframeSource(docs)
docs <- Corpus(docs)
# Preprocessing:
docs <- tm_map(docs, removeWords, stopwords("english")) # remove stop words (the most common word in a language that can be find in any document)
View(docs)
docs <- tm_map(docs, removePunctuation) # remove pnctuation
docs <- tm_map(docs, stemDocument) # perform stemming (reducing inflected and derived words to their root form)
docs <- tm_map(docs, removeNumbers) # remove all numbers
docs <- tm_map(docs, stripWhitespace) # remove redundant spaces
install.packages('SnowballC')
library(SnowballC)
path <- '~/gitfiles/R_playground/FIT5201/Assignments/Ass2/datasets/Task2A.txt'
text <- readLines(path)
docs <- strsplit(text, '\t')
labels <- unlist(lapply(docs, function(x) x[1]))
texts <- unlist(lapply(docs, function(x) x[2]))
indices <- c(1:length(texts))
docs <- data.frame(doc_id = indices, text=texts)
# create a corpus
docs <- DataframeSource(docs)
docs <- Corpus(docs)
docs <- tm_map(docs, removeWords, stopwords("english")) # remove stop words (the most common word in a language that can be find in any document)
docs <- tm_map(docs, removePunctuation) # remove pnctuation
docs <- tm_map(docs, stemDocument) # perform stemming (reducing inflected and derived words to their root form)
docs <- tm_map(docs, removeNumbers) # remove all numbers
docs <- tm_map(docs, stripWhitespace) # remove redundant spaces
View(docs)
m <- as.matrix(dtm)
rownames(m) <- 1:nrow(m)
